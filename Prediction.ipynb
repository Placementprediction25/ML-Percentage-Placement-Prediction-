{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9858608e-dc93-4163-9f03-9d209d755471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Tenth  Twelfth  CGPA Branch  Internships  Projects  Aptitude  Soft skills  \\\n",
      "0  79.97    60.04   NaN    CSE            1         2     62.82        22.40   \n",
      "1  73.62    77.76  6.87  CIVIL            1         0     42.10        73.96   \n",
      "2  81.48    85.22  8.15     IT            1         5     56.08        54.59   \n",
      "3  90.23    81.31  7.07     IT            1         2     71.85        89.45   \n",
      "4  72.66    84.93  7.94     IT            1         2     58.22        82.04   \n",
      "\n",
      "   Leadership  Extracurricular  Certifications  Backlogs    DSA  Lang  \\\n",
      "0       64.73            41.01               2         1  31.82     2   \n",
      "1       62.72            17.85               1         0  59.50     3   \n",
      "2       69.44            62.06               1         1  65.57     2   \n",
      "3       69.47            44.74               0         1  26.38     3   \n",
      "4       74.46            52.91               2         0  66.35     1   \n",
      "\n",
      "   Probability  \n",
      "0         46.4  \n",
      "1         52.7  \n",
      "2         60.4  \n",
      "3         58.4  \n",
      "4         60.9  \n",
      "\n",
      "Shape: (11000, 15)\n",
      "\n",
      "Columns: Index(['Tenth', 'Twelfth', 'CGPA', 'Branch', 'Internships', 'Projects',\n",
      "       'Aptitude', 'Soft skills', 'Leadership', 'Extracurricular',\n",
      "       'Certifications', 'Backlogs', 'DSA', 'Lang', 'Probability'],\n",
      "      dtype='object')\n",
      "\n",
      "Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Tenth            11000 non-null  float64\n",
      " 1   Twelfth          11000 non-null  float64\n",
      " 2   CGPA             10999 non-null  float64\n",
      " 3   Branch           11000 non-null  object \n",
      " 4   Internships      11000 non-null  int64  \n",
      " 5   Projects         11000 non-null  int64  \n",
      " 6   Aptitude         11000 non-null  float64\n",
      " 7   Soft skills      11000 non-null  float64\n",
      " 8   Leadership       11000 non-null  float64\n",
      " 9   Extracurricular  11000 non-null  float64\n",
      " 10  Certifications   11000 non-null  int64  \n",
      " 11  Backlogs         11000 non-null  int64  \n",
      " 12  DSA              11000 non-null  float64\n",
      " 13  Lang             11000 non-null  int64  \n",
      " 14  Probability      11000 non-null  float64\n",
      "dtypes: float64(9), int64(5), object(1)\n",
      "memory usage: 1.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "old_min = df['Probability'].min()\n",
    "old_max = df['Probability'].max()\n",
    "\n",
    "new_min = 50\n",
    "new_max = 95\n",
    "\n",
    "df['Probability_scaled'] = ((df['Probability'] - old_min) / (old_max - old_min)) * (new_max - new_min) + new_min\n",
    "\n",
    "# Preview\n",
    "print(data.head())\n",
    "print(\"\\nShape:\", data.shape)\n",
    "print(\"\\nColumns:\", data.columns)\n",
    "print(\"\\nInfo:\")\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da73c8d8-9926-428a-8c53-c06fe4dc02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(\"Probability\", axis=1)   # replace with your actual target column\n",
    "y = data[\"Probability\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df427c7d-19d3-4951-8cc4-2b0a49c8b7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Identify categorical & numeric columns\n",
    "cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "num_cols = X.select_dtypes(exclude=[\"object\"]).columns\n",
    "\n",
    "# Preprocessing: OneHot for categorical + Scaling for numeric\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1af6df3-9b02-4c55-9967-37f9a6349f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = y.value_counts()\n",
    "rare_classes = counts[counts < 2].index\n",
    "mask = ~y.isin(rare_classes)\n",
    "\n",
    "X = X[mask]\n",
    "y = y[mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5e7b859-f2ee-42a1-9264-4141dfca3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "for train_idx, test_idx in split.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df972f05-9a99-425a-8600-4f856db138fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m y_pred = clf.predict(X_test)\n\u001b[32m      4\u001b[39m y_proba = clf.predict_proba(X_test)[:, \u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:418\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    411\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    412\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSum of y is not strictly positive which \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    413\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis necessary for Poisson regression.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    414\u001b[39m         )\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._n_samples, \u001b[38;5;28mself\u001b[39m.n_outputs_ = y.shape\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m y, expanded_class_weight = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_y_class_weight\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(y, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) != DOUBLE \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y.flags.contiguous:\n\u001b[32m    421\u001b[39m     y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:830\u001b[39m, in \u001b[36mForestClassifier._validate_y_class_weight\u001b[39m\u001b[34m(self, y)\u001b[39m\n\u001b[32m    829\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_validate_y_class_weight\u001b[39m(\u001b[38;5;28mself\u001b[39m, y):\n\u001b[32m--> \u001b[39m\u001b[32m830\u001b[39m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    832\u001b[39m     y = np.copy(y)\n\u001b[32m    833\u001b[39m     expanded_class_weight = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:221\u001b[39m, in \u001b[36mcheck_classification_targets\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m    213\u001b[39m y_type = type_of_target(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    215\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    216\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmultilabel-sequences\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    220\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Maybe you are trying to fit a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mclassifier, which expects discrete classes on a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    224\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mregression target with continuous values.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    225\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Unknown label type: continuous. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55af7733-5e5e-4087-b491-5d343389795a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
